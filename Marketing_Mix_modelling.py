# -*- coding: utf-8 -*-
"""MMMMM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n-RV3fE2CQiTeU965feFMeNH3oQrSzz6
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("veer06b/marrket-mix-dataset")
print("Path to dataset files:", path)

import pandas as pd
import os

# List files in the downloaded directory
print(os.listdir(path))
# Load the dataset
df = pd.read_csv(f'{path}/mktmix.csv')

# Display the first few rows
df.head(50)

import pandas as pd
import numpy as np
import pymc as pm
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
df = pd.read_csv(f'{path}/mktmix.csv')

# For simplicity, we'll use a subset of the data
# df = df.head(150) # Use first ~3 years of data

# Display the first few rows
print(df.head())

# Visualize the data to understand it
fig, axs = plt.subplots(3, 1, figsize=(12, 8), sharex=True)
sns.lineplot(data=df, x=df.index, y='NewVolSales', ax=axs[0], color='b').set(title='Weekly Sales')
sns.lineplot(data=df, x=df.index, y='TV', ax=axs[1], color='r').set(title='TV Spend')
sns.lineplot(data=df, x=df.index, y='Radio ', ax=axs[2], color='g').set(title='Radio Spend')
plt.tight_layout()
plt.show()

def geometric_adstock(spend, decay_rate):
    """
    Calculates the geometric adstock effect.

    Args:
    - spend (pd.Series): A series of media spend over time.
    - decay_rate (float): The rate at which adstock decays (0 to 1).

    Returns:
    - pd.Series: The adstocked spend.
    """
    adstocked_spend = np.zeros_like(spend)
    adstocked_spend[0] = spend[0]
    for t in range(1, len(spend)):
        adstocked_spend[t] = spend[t] + decay_rate * adstocked_spend[t-1]
    return adstocked_spend

# Apply adstock to our media channels
# Decay rates are hyperparameters you can tune. Common values are 0.5 for TV, 0.2 for Radio etc.
df['tv_adstock'] = geometric_adstock(df['TV'].values, decay_rate=0.5)
df['radio_adstock'] = geometric_adstock(df['Radio '].values, decay_rate=0.3)
# df['social_media_adstock'] = geometric_adstock(df['Social Media'].values, decay_rate=0.1)

# Apply a log transformation to model saturation. Add 1 to avoid log(0).
df['tv_saturated'] = np.log(df['tv_adstock'] + 1)
df['radio_saturated'] = np.log(df['radio_adstock'] + 1)
# df['social_media_saturated'] = np.log(df['social_media_adstock'] + 1)

# Prepare data for the model
X1 = df['tv_saturated'].values
X2 = df['radio_saturated'].fillna(df['radio_saturated'].mean()).values
y = df['NewVolSales'].values

with pm.Model() as mmm_model:
    # --- Priors ---
    # These are our beliefs about the parameters before seeing the data.

    # Baseline sales (Intercept)
    baseline = pm.Normal('baseline', mu=np.mean(y), sigma=np.std(y))

    # Channel coefficients (betas) - we believe they are positive
    beta_tv = pm.HalfNormal('beta_tv', sigma=5)
    beta_radio = pm.HalfNormal('beta_radio', sigma=5)

    # Synergy effect between TV and Radio
    # We are neutral about synergy, so we use a Normal distribution centered at 0
    synergy_tv_radio = pm.Normal('synergy_tv_radio', mu=0, sigma=5)

    # Model error
    sigma = pm.HalfNormal('sigma', sigma=np.std(y))

    # --- Likelihood ---
    # This is the model equation that links our features to the sales data.

    expected_sales = (
        baseline +
        beta_tv * X1 +
        beta_radio * X2 +
        synergy_tv_radio * X1 * X2 # Interaction term for synergy
    )

    # The likelihood function (how the data is distributed given the parameters)
    sales = pm.Normal('sales', mu=expected_sales, sigma=sigma, observed=y)

    # --- MCMC Sampling ---
    # This is the training step. PyMC will find the best posterior distributions for our parameters.
    print("Starting MCMC sampling...")
    idata = pm.sample(2000, tune=1000, chains=4, cores=1)
    print("Sampling complete.")

# --- Visualize the Posterior Distributions ---
# This shows the range of likely values for each parameter.
pm.plot_posterior(
    idata,
    var_names=['baseline', 'beta_tv', 'beta_radio', 'synergy_tv_radio']
)
plt.suptitle("Posterior Distributions of Model Parameters", y=1.02)
plt.show()

# --- Decompose Contributions ---
# Calculate the average contribution of each component to sales
baseline_contribution = idata.posterior['baseline'].mean().item()
tv_contribution = idata.posterior['beta_tv'].mean().item() * df['tv_saturated'].mean().item()
radio_contribution = idata.posterior['beta_radio'].mean().item() * df['radio_saturated'].fillna(df['radio_saturated'].mean()).mean().item()
synergy_contribution = idata.posterior['synergy_tv_radio'].mean().item() * df['tv_saturated'].mean().item() * df['radio_saturated'].fillna(df['radio_saturated'].mean()).mean().item()

contributions = {
    'Baseline': baseline_contribution,
    'TV': tv_contribution,
    'Radio': radio_contribution,
    'TV-Radio Synergy': synergy_contribution
}

# Plot the contributions
plt.figure(figsize=(10, 6))
plt.bar(contributions.keys(), contributions.values())
plt.title('Average Contribution to Sales')
plt.ylabel('Average Sales Contribution')
plt.show()

print("\n--- Model Insights ---")
print(f"The baseline sales (sales with no marketing) are around: {baseline_contribution:.2f}")
if synergy_contribution > 0:
    print("There is a POSITIVE synergy effect between TV and Radio advertising.")
else:
    print("There is a NEGATIVE or no synergy effect between TV and Radio advertising.")









# --- Install & Imports ---
# pip install pymc seaborn matplotlib scikit-learn kagglehub

import kagglehub
import pandas as pd
import numpy as np
import pymc as pm
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
import os

# --- Download dataset ---
path = kagglehub.dataset_download("veer06b/marrket-mix-dataset")
print("Path to dataset files:", path)

# Load and inspect data
df = pd.read_csv(f"{path}/mktmix.csv")
print(df.head())

# --- Preprocessing ---
# Clean trailing space in 'Radio '
df['Radio'] = df['Radio ']
del df['Radio ']

# --- Adstock function ---
def geometric_adstock(spend, decay_rate):
    adstocked = []
    carryover = 0
    for s in spend:
        val = s + decay_rate * carryover
        adstocked.append(val)
        carryover = val
    return np.array(adstocked)

# Apply adstock
df['tv_adstock'] = geometric_adstock(df['TV'], decay_rate=0.5)
df['radio_adstock'] = geometric_adstock(df['Radio'], decay_rate=0.3)

# Saturation: log(1 + x)
df['tv_saturated'] = np.log1p(df['tv_adstock'])
df['radio_saturated'] = np.log1p(df['radio_adstock'].fillna(df['radio_adstock'].mean())) # Fill NaN values here

# --- Standardize media features ---
scaler = StandardScaler()
df[['tv_saturated', 'radio_saturated']] = scaler.fit_transform(df[['tv_saturated', 'radio_saturated']])

# Model inputs
X1 = df['tv_saturated'].values
X2 = df['radio_saturated'].values
y = df['NewVolSales'].values # Correct sales column name

# --- PyMC Model ---
with pm.Model() as mmm_model:
    # Priors
    baseline = pm.Normal('baseline', mu=np.mean(y), sigma=10)
    beta_tv = pm.Normal('beta_tv', mu=0, sigma=5)
    beta_radio = pm.Normal('beta_radio', mu=0, sigma=5)
    synergy_tv_radio = pm.Normal('synergy_tv_radio', mu=0, sigma=2)
    sigma = pm.HalfNormal('sigma', sigma=10)

    # Likelihood
    expected_sales = (
        baseline +
        beta_tv * X1 +
        beta_radio * X2 +
        synergy_tv_radio * X1 * X2
    )
    sales = pm.Normal('sales', mu=expected_sales, sigma=sigma, observed=y)

    print("Starting MCMC sampling...")
    idata = pm.sample(2000, tune=1000, chains=4, cores=1)
    print("Sampling complete.")

# --- Posterior Visualization ---
pm.plot_posterior(
    idata,
    var_names=['baseline', 'beta_tv', 'beta_radio', 'synergy_tv_radio']
)
plt.suptitle("Posterior Distributions of Model Parameters", y=1.02)
plt.show()

# --- Sales Contribution Decomposition ---
baseline_contribution = idata.posterior['baseline'].mean().item()
tv_contribution = idata.posterior['beta_tv'].mean().item() * df['tv_saturated'].mean()
radio_contribution = idata.posterior['beta_radio'].mean().item() * df['radio_saturated'].mean()
synergy_contribution = idata.posterior['synergy_tv_radio'].mean().item() * (
    df['tv_saturated'] * df['radio_saturated']
).mean()

contributions = {
    'Baseline': baseline_contribution,
    'TV': tv_contribution,
    'Radio': radio_contribution,
    'TV-Radio Synergy': synergy_contribution
}

# --- Plot Contributions ---
plt.figure(figsize=(10, 6))
plt.bar(contributions.keys(), contributions.values(), color='steelblue')
plt.title('Average Contribution to Sales')
plt.ylabel('Sales Contribution')
plt.grid(True, axis='y', linestyle='--', alpha=0.5)
plt.show()

# --- Insights ---
print("\n--- Model Insights ---")
print(f"Baseline sales (no marketing): {baseline_contribution:.2f}")
print(f"TV contribution: {tv_contribution:.2f}")
print(f"Radio contribution: {radio_contribution:.2f}")
print(f"TV-Radio Synergy: {synergy_contribution:.2f}")

if synergy_contribution > 0:
    print("ðŸŸ¢ Positive synergy detected between TV and Radio.")
else:
    print("ðŸ”´ Negative or no synergy between TV and Radio.")

# --- Install & Imports ---
# pip install pymc seaborn matplotlib scikit-learn kagglehub

import kagglehub
import pandas as pd
import numpy as np
import pymc as pm
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
import os

# --- Download dataset ---
path = kagglehub.dataset_download("veer06b/marrket-mix-dataset")
print("Path to dataset files:", path)

# Load and inspect data
df = pd.read_csv(f"{path}/mktmix.csv")
print(df.head())

# --- Preprocessing ---
df['Radio'] = df['Radio ']
del df['Radio ']

# --- Adstock Function ---
def geometric_adstock(spend, decay_rate):
    adstocked = []
    carryover = 0
    for s in spend:
        val = s + decay_rate * carryover
        adstocked.append(val)
        carryover = val
    return np.array(adstocked)

# Apply adstock
df['tv_adstock'] = geometric_adstock(df['TV'], decay_rate=0.5)
df['radio_adstock'] = geometric_adstock(df['Radio'], decay_rate=0.3)

# Saturation (diminishing returns)
df['tv_saturated'] = np.log1p(df['tv_adstock'])
df['radio_saturated'] = np.log1p(df['radio_adstock'].fillna(df['radio_adstock'].mean()))

# Standardize
scaler = StandardScaler()
df[['tv_saturated', 'radio_saturated']] = scaler.fit_transform(df[['tv_saturated', 'radio_saturated']])

# Model inputs
X1 = df['tv_saturated'].values
X2 = df['radio_saturated'].values
y = df['NewVolSales'].values

# --- PyMC Bayesian Model ---
with pm.Model() as mmm_model:
    baseline = pm.Normal('baseline', mu=np.mean(y), sigma=10)
    beta_tv = pm.Normal('beta_tv', mu=0, sigma=5)
    beta_radio = pm.Normal('beta_radio', mu=0, sigma=5)
    synergy_tv_radio = pm.Normal('synergy_tv_radio', mu=0, sigma=2)
    sigma = pm.HalfNormal('sigma', sigma=10)

    expected_sales = (
        baseline +
        beta_tv * X1 +
        beta_radio * X2 +
        synergy_tv_radio * X1 * X2
    )

    sales = pm.Normal('sales', mu=expected_sales, sigma=sigma, observed=y)

    print("Starting MCMC sampling...")
    idata = pm.sample(2000, tune=1000, chains=4, cores=1, progressbar=True)
    print("Sampling complete.")

# --- Posterior Visualization ---
pm.plot_posterior(idata, var_names=['baseline', 'beta_tv', 'beta_radio', 'synergy_tv_radio'])
plt.suptitle("Posterior Distributions of Model Parameters", y=1.02)
plt.show()

# --- Sales Contribution Decomposition ---
baseline_contribution = idata.posterior['baseline'].mean().item()
beta_tv_mean = idata.posterior['beta_tv'].mean().item()
beta_radio_mean = idata.posterior['beta_radio'].mean().item()
synergy_contribution = idata.posterior['synergy_tv_radio'].mean().item() * (df['tv_saturated'] * df['radio_saturated']).mean()

tv_contribution = beta_tv_mean * df['tv_saturated'].mean()
radio_contribution = beta_radio_mean * df['radio_saturated'].mean()

contributions = {
    'Baseline': baseline_contribution,
    'TV': tv_contribution,
    'Radio': radio_contribution,
    'TV-Radio Synergy': synergy_contribution
}

# --- Plot Contributions ---
plt.figure(figsize=(10, 6))
plt.bar(contributions.keys(), contributions.values(), color='steelblue')
plt.title('Average Contribution to Sales')
plt.ylabel('Sales Contribution')
plt.grid(True, axis='y', linestyle='--', alpha=0.5)
plt.show()

# --- Print Insights ---
print("\n--- Model Insights ---")
print(f"Baseline sales (no marketing): {baseline_contribution:.2f}")
print(f"TV contribution: {tv_contribution:.2f}")
print(f"Radio contribution: {radio_contribution:.2f}")
print(f"TV-Radio Synergy: {synergy_contribution:.2f}")
if synergy_contribution > 0:
    print("ðŸŸ¢ Positive synergy detected between TV and Radio.")
else:
    print("ðŸ”´ Negative or no synergy between TV and Radio.")

# --- Marginal ROI Calculation ---
tv_std = df['tv_saturated'].std()
radio_std = df['radio_saturated'].std()

roi_tv = beta_tv_mean / tv_std
roi_radio = beta_radio_mean / radio_std

print("\n--- Marginal ROI Estimates ---")
print(f"TV Marginal ROI: {roi_tv:.2f} units of sales per $1 spend")
print(f"Radio Marginal ROI: {roi_radio:.2f} units of sales per $1 spend")

# --- Optimal Budget Allocation ---
total_budget = 100_000  # Example budget
total_roi = roi_tv + roi_radio
tv_budget = (roi_tv / total_roi) * total_budget
radio_budget = (roi_radio / total_roi) * total_budget

print("\n--- Recommended Budget Allocation (Based on ROI) ---")
print(f"Total Budget: ${total_budget:,.0f}")
print(f"Allocate to TV: ${tv_budget:,.0f}")
print(f"Allocate to Radio: ${radio_budget:,.0f}")

# --- Media Mix Simulator Function ---
def simulate_sales(tv_spend, radio_spend, decay_tv=0.5, decay_radio=0.3):
    tv_adstock = geometric_adstock([tv_spend]*10, decay_tv)[-1]
    radio_adstock = geometric_adstock([radio_spend]*10, decay_radio)[-1]

    tv_sat = np.log1p(tv_adstock)
    radio_sat = np.log1p(radio_adstock)

    tv_std_val = (tv_sat - df['tv_saturated'].mean()) / df['tv_saturated'].std()
    radio_std_val = (radio_sat - df['radio_saturated'].mean()) / df['radio_saturated'].std()

    synergy_mean = idata.posterior['synergy_tv_radio'].mean().item()
    expected = (
        baseline_contribution +
        beta_tv_mean * tv_std_val +
        beta_radio_mean * radio_std_val +
        synergy_mean * tv_std_val * radio_std_val
    )
    return expected

# --- Example What-if Simulation ---
sim_sales = simulate_sales(tv_spend=30000, radio_spend=20000)
print("\n--- What-if Simulation ---")
print(f"Expected sales with TV=$30,000 and Radio=$20,000: {sim_sales:.2f}")

# --- ROI vs Spend Plot ---
tv_range = np.linspace(0, 100000, 50)
radio_range = np.linspace(0, 100000, 50)
tv_sim = [simulate_sales(tv, 20000) for tv in tv_range]
radio_sim = [simulate_sales(30000, r) for r in radio_range]

plt.figure(figsize=(12, 5))
plt.plot(tv_range, tv_sim, label='Varying TV (Radio fixed at $20k)')
plt.plot(radio_range, radio_sim, label='Varying Radio (TV fixed at $30k)')
plt.xlabel('Media Spend ($)')
plt.ylabel('Expected Sales')
plt.title('What-if Sales Simulation')
plt.legend()
plt.grid(True)
plt.show()

# --- Install & Imports ---
# pip install pymc seaborn matplotlib scikit-learn kagglehub

import kagglehub
import pandas as pd
import numpy as np
import pymc as pm
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
import os

# --- Download dataset ---
path = kagglehub.dataset_download("veer06b/marrket-mix-dataset")
print("Path to dataset files:", path)

# Load and inspect data
df = pd.read_csv(f"{path}/mktmix.csv")
print(df.head())

# --- Preprocessing ---
df['Radio'] = df['Radio ']  # Clean column name
del df['Radio ']

# --- Adstock Function ---
def geometric_adstock(spend, decay_rate):
    adstocked = []
    carryover = 0
    for s in spend:
        val = s + decay_rate * carryover
        adstocked.append(val)
        carryover = val
    return np.array(adstocked)

# Apply adstock
df['tv_adstock'] = geometric_adstock(df['TV'], decay_rate=0.5)
df['radio_adstock'] = geometric_adstock(df['Radio'], decay_rate=0.3)

# Saturation
df['tv_saturated'] = np.log1p(df['tv_adstock'])
df['radio_saturated'] = np.log1p(df['radio_adstock'].fillna(df['radio_adstock'].mean()))

# ðŸ‘‰ Save raw means before standardizing (for contribution calc later)
tv_sat_mean_raw = df['tv_saturated'].mean()
radio_sat_mean_raw = df['radio_saturated'].mean()
tv_radio_synergy_raw = (df['tv_saturated'] * df['radio_saturated']).mean()

# Standardize for modeling
scaler = StandardScaler()
df[['tv_saturated', 'radio_saturated']] = scaler.fit_transform(df[['tv_saturated', 'radio_saturated']])

# Model inputs
X1 = df['tv_saturated'].values
X2 = df['radio_saturated'].values
y = df['NewVolSales'].values

# --- PyMC Bayesian Model ---
with pm.Model() as mmm_model:
    baseline = pm.Normal('baseline', mu=np.mean(y), sigma=10)
    beta_tv = pm.Normal('beta_tv', mu=0, sigma=5)
    beta_radio = pm.Normal('beta_radio', mu=0, sigma=5)
    synergy_tv_radio = pm.Normal('synergy_tv_radio', mu=0, sigma=2)
    sigma = pm.HalfNormal('sigma', sigma=10)

    expected_sales = (
        baseline +
        beta_tv * X1 +
        beta_radio * X2 +
        synergy_tv_radio * X1 * X2
    )

    sales = pm.Normal('sales', mu=expected_sales, sigma=sigma, observed=y)

    print("Starting MCMC sampling...")
    idata = pm.sample(2000, tune=1000, chains=4, cores=1)
    print("Sampling complete.")

# --- Posterior Visualization ---
pm.plot_posterior(idata, var_names=['baseline', 'beta_tv', 'beta_radio', 'synergy_tv_radio'])
plt.suptitle("Posterior Distributions of Model Parameters", y=1.02)
plt.show()

# --- Sales Contribution Decomposition ---
baseline_contribution = idata.posterior['baseline'].mean().item()
beta_tv_mean = idata.posterior['beta_tv'].mean().item()
beta_radio_mean = idata.posterior['beta_radio'].mean().item()
synergy_mean = idata.posterior['synergy_tv_radio'].mean().item()

# âœ… Use raw means here
tv_contribution = beta_tv_mean * tv_sat_mean_raw
radio_contribution = beta_radio_mean * radio_sat_mean_raw
synergy_contribution = synergy_mean * tv_radio_synergy_raw

contributions = {
    'Baseline': baseline_contribution,
    'TV': tv_contribution,
    'Radio': radio_contribution,
    'TV-Radio Synergy': synergy_contribution
}

# --- Plot Contributions ---
plt.figure(figsize=(10, 6))
plt.bar(contributions.keys(), contributions.values(), color='steelblue')
plt.title('Average Contribution to Sales')
plt.ylabel('Sales Contribution')
plt.grid(True, axis='y', linestyle='--', alpha=0.5)
plt.show()

# --- Print Insights ---
print("\n--- Model Insights ---")
print(f"Baseline sales (no marketing): {baseline_contribution:.2f}")
print(f"TV contribution: {tv_contribution:.2f}")
print(f"Radio contribution: {radio_contribution:.2f}")
print(f"TV-Radio Synergy: {synergy_contribution:.2f}")
if synergy_contribution > 0:
    print("ðŸŸ¢ Positive synergy detected between TV and Radio.")
else:
    print("ðŸ”´ Negative or no synergy between TV and Radio.")

# --- Marginal ROI Calculation ---
tv_std = df['tv_saturated'].std()
radio_std = df['radio_saturated'].std()

roi_tv = beta_tv_mean / tv_std
roi_radio = beta_radio_mean / radio_std

print("\n--- Marginal ROI Estimates ---")
print(f"TV Marginal ROI: {roi_tv:.2f} units of sales per $1 spend")
print(f"Radio Marginal ROI: {roi_radio:.2f} units of sales per $1 spend")

# --- Optimal Budget Allocation ---
total_budget = 100_000  # Example budget
total_roi = roi_tv + roi_radio
tv_budget = (roi_tv / total_roi) * total_budget
radio_budget = (roi_radio / total_roi) * total_budget

print("\n--- Recommended Budget Allocation (Based on ROI) ---")
print(f"Total Budget: ${total_budget:,.0f}")
print(f"Allocate to TV: ${tv_budget:,.0f}")
print(f"Allocate to Radio: ${radio_budget:,.0f}")

# --- Media Mix Simulator Function ---
def simulate_sales(tv_spend, radio_spend, decay_tv=0.5, decay_radio=0.3):
    tv_adstock = geometric_adstock([tv_spend]*10, decay_tv)[-1]
    radio_adstock = geometric_adstock([radio_spend]*10, decay_radio)[-1]

    tv_sat = np.log1p(tv_adstock)
    radio_sat = np.log1p(radio_adstock)

    tv_std_val = (tv_sat - tv_sat_mean_raw) / tv_std
    radio_std_val = (radio_sat - radio_sat_mean_raw) / radio_std

    expected = (
        baseline_contribution +
        beta_tv_mean * tv_std_val +
        beta_radio_mean * radio_std_val +
        synergy_mean * tv_std_val * radio_std_val
    )
    return expected

# --- Example What-if Simulation ---
sim_sales = simulate_sales(tv_spend=30000, radio_spend=20000)
print("\n--- What-if Simulation ---")
print(f"Expected sales with TV=$30,000 and Radio=$20,000: {sim_sales:.2f}")

# --- ROI vs Spend Plot ---
tv_range = np.linspace(0, 100000, 50)
radio_range = np.linspace(0, 100000, 50)
tv_sim = [simulate_sales(tv, 20000) for tv in tv_range]
radio_sim = [simulate_sales(30000, r) for r in radio_range]

plt.figure(figsize=(12, 5))
plt.plot(tv_range, tv_sim, label='Varying TV (Radio fixed at $20k)')
plt.plot(radio_range, radio_sim, label='Varying Radio (TV fixed at $30k)')
plt.xlabel('Media Spend ($)')
plt.ylabel('Expected Sales')
plt.title('What-if Sales Simulation')
plt.legend()
plt.grid(True)
plt.show()

# --- Install Required Packages ---
# pip install pymc seaborn matplotlib scikit-learn pandas numpy

import pandas as pd
import numpy as np
import pymc as pm
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
# --- Download dataset ---
path = kagglehub.dataset_download("veer06b/marrket-mix-dataset")
print("Path to dataset files:", path)

# Load and inspect data
df = pd.read_csv(f"{path}/mktmix.csv")
# --- Load Dataset ---
#df = pd.read_csv("mktmix.csv")  # Place file in working directory
df['Radio'] = df['Radio ']
del df['Radio ']

# --- Adstock Function ---
def geometric_adstock(spend, decay_rate):
    adstocked = []
    carryover = 0
    for s in spend:
        val = s + decay_rate * carryover
        adstocked.append(val)
        carryover = val
    return np.array(adstocked)

# --- Hill Saturation Function ---
def hill_transform(x, alpha, gamma):
    return (x ** alpha) / (x ** alpha + gamma ** alpha)

# --- Apply Adstock and Hill Transformation ---
df['tv_adstock'] = geometric_adstock(df['TV'], decay_rate=0.5)
df['radio_adstock'] = geometric_adstock(df['Radio'], decay_rate=0.3)

alpha_tv, gamma_tv = 1.5, 1000
alpha_radio, gamma_radio = 1.3, 700

df['tv_saturated'] = hill_transform(df['tv_adstock'], alpha_tv, gamma_tv)
df['radio_saturated'] = hill_transform(df['radio_adstock'].fillna(df['radio_adstock'].mean()), alpha_radio, gamma_radio)

# Save raw means for contribution calc
tv_sat_mean_raw = df['tv_saturated'].mean()
radio_sat_mean_raw = df['radio_saturated'].mean()
tv_radio_synergy_raw = (df['tv_saturated'] * df['radio_saturated']).mean()

# Standardize features
scaler = StandardScaler()
df[['tv_saturated', 'radio_saturated']] = scaler.fit_transform(df[['tv_saturated', 'radio_saturated']])
tv_std = df['tv_saturated'].std()
radio_std = df['radio_saturated'].std()

# Prepare input arrays
X1 = df['tv_saturated'].values
X2 = df['radio_saturated'].values
y = df['NewVolSales'].values

# --- Bayesian Model ---
with pm.Model() as mmm_model:
    baseline = pm.Normal('baseline', mu=np.mean(y), sigma=10)
    beta_tv = pm.Normal('beta_tv', mu=0, sigma=5)
    beta_radio = pm.Normal('beta_radio', mu=0, sigma=5)
    synergy_tv_radio = pm.Normal('synergy_tv_radio', mu=0, sigma=2)
    sigma = pm.HalfNormal('sigma', sigma=10)

    expected_sales = baseline + beta_tv * X1 + beta_radio * X2 + synergy_tv_radio * X1 * X2
    sales = pm.Normal('sales', mu=expected_sales, sigma=sigma, observed=y)

    print("Sampling...")
    idata = pm.sample(2000, tune=1000, chains=4, cores=1)

# Posterior Plots
pm.plot_posterior(idata, var_names=['baseline', 'beta_tv', 'beta_radio', 'synergy_tv_radio'])
plt.suptitle("Posterior Distributions of Model Parameters", y=1.02)
plt.show()

# Posterior Predictive Check
with mmm_model:
    ppc = pm.sample_posterior_predictive(idata, var_names=["sales"])

plt.figure(figsize=(10, 5))
sns.histplot(y, label="Observed", stat='density', color='blue', kde=True)
sns.histplot(ppc['sales'].mean(axis=0), label="Predicted", stat='density', color='orange', kde=True)
plt.title("Posterior Predictive Check")
plt.legend()
plt.show()

# --- Contributions ---
baseline_contribution = idata.posterior['baseline'].mean().item()
beta_tv_mean = idata.posterior['beta_tv'].mean().item()
beta_radio_mean = idata.posterior['beta_radio'].mean().item()
synergy_mean = idata.posterior['synergy_tv_radio'].mean().item()

tv_contribution = beta_tv_mean * tv_sat_mean_raw
radio_contribution = beta_radio_mean * radio_sat_mean_raw
synergy_contribution = synergy_mean * tv_radio_synergy_raw

contributions = {
    'Baseline': baseline_contribution,
    'TV': tv_contribution,
    'Radio': radio_contribution,
    'TV-Radio Synergy': synergy_contribution
}

plt.figure(figsize=(10, 6))
plt.bar(contributions.keys(), contributions.values(), color='steelblue')
plt.title('Average Contribution to Sales')
plt.ylabel('Sales Contribution')
plt.grid(True, axis='y', linestyle='--', alpha=0.5)
plt.show()

# ROI Estimates
roi_tv = beta_tv_mean / tv_std
roi_radio = beta_radio_mean / radio_std

print("\n--- ROI Estimates ---")
print(f"TV ROI: {roi_tv:.2f}")
print(f"Radio ROI: {roi_radio:.2f}")

# Budget Allocation
total_budget = 100_000
total_roi = roi_tv + roi_radio
tv_budget = (roi_tv / total_roi) * total_budget
radio_budget = (roi_radio / total_roi) * total_budget

print("\n--- Budget Allocation ---")
print(f"TV: ${tv_budget:,.0f}")
print(f"Radio: ${radio_budget:,.0f}")

# --- Simulation Function ---
def simulate_sales(tv_spend, radio_spend, decay_tv=0.5, decay_radio=0.3):
    tv_adstock = geometric_adstock([tv_spend]*10, decay_tv)[-1]
    radio_adstock = geometric_adstock([radio_spend]*10, decay_radio)[-1]

    tv_sat = hill_transform(tv_adstock, alpha_tv, gamma_tv)
    radio_sat = hill_transform(radio_adstock, alpha_radio, gamma_radio)

    tv_std_val = (tv_sat - tv_sat_mean_raw) / tv_std
    radio_std_val = (radio_sat - radio_sat_mean_raw) / radio_std

    expected = (
        baseline_contribution +
        beta_tv_mean * tv_std_val +
        beta_radio_mean * radio_std_val +
        synergy_mean * tv_std_val * radio_std_val
    )
    return expected

# What-if Simulation
sim_sales = simulate_sales(tv_spend=30000, radio_spend=20000)
print(f"\nExpected Sales for TV=$30k, Radio=$20k: {sim_sales:.2f}")

# ROI vs Spend Plot
tv_range = np.linspace(0, 100000, 50)
radio_range = np.linspace(0, 100000, 50)
tv_sim = [simulate_sales(tv, 20000) for tv in tv_range]
radio_sim = [simulate_sales(30000, r) for r in radio_range]

plt.figure(figsize=(12, 5))
plt.plot(tv_range, tv_sim, label='TV Varying (Radio $20k)')
plt.plot(radio_range, radio_sim, label='Radio Varying (TV $30k)')
plt.xlabel('Spend ($)')
plt.ylabel('Expected Sales')
plt.title('Sales Simulation')
plt.legend()
plt.grid(True)
plt.show()

# --- Elasticity Curve ---
def elasticity_curve(media='TV'):
    spends = np.linspace(100, 100000, 100)
    base = 20000 if media == 'TV' else 30000
    elasticities = []

    for s in spends:
        if media == 'TV':
            e1 = simulate_sales(s, base)
            e2 = simulate_sales(s + 1000, base)
        else:
            e1 = simulate_sales(base, s)
            e2 = simulate_sales(base, s + 1000)

        pct_sales = (e2 - e1) / e1
        pct_spend = 1000 / s
        elasticity = pct_sales / pct_spend
        elasticities.append(elasticity)

    plt.plot(spends, elasticities, label=f'{media} Elasticity')
    plt.xlabel(f'{media} Spend ($)')
    plt.ylabel('Elasticity')
    plt.title(f'{media} Elasticity Curve')
    plt.grid(True)
    plt.legend()
    plt.show()

elasticity_curve('TV')
elasticity_curve('Radio')

# --- Install Required Packages if not already ---
# pip install pymc seaborn matplotlib scikit-learn pandas numpy arviz kagglehub

import pandas as pd
import numpy as np
import pymc as pm
import matplotlib.pyplot as plt
import seaborn as sns
import arviz as az
from sklearn.preprocessing import StandardScaler
import kagglehub

path = kagglehub.dataset_download("veer06b/marrket-mix-dataset")
print("Path to dataset files:", path)

# Load and inspect data
df = pd.read_csv(f"{path}/mktmix.csv")
df['Radio'] = df['Radio ']  # Clean column name
del df['Radio ']

# --- Adstock Function ---
def geometric_adstock(spend, decay_rate):
    adstocked = []
    carryover = 0
    # Handle potential NaNs in input spend before adstock calculation
    spend_clean = np.nan_to_num(spend, nan=0.0)
    for s in spend_clean:
        val = s + decay_rate * carryover
        adstocked.append(val)
        carryover = val
    return np.array(adstocked)

# --- Apply Adstock ---
# Handle NaNs in original TV and Radio spend before adstock
df['TV'].fillna(df['TV'].mean(), inplace=True) # Or a more sophisticated imputation
df['Radio'].fillna(df['Radio'].mean(), inplace=True) # Or a more sophisticated imputation


df['tv_adstock'] = geometric_adstock(df['TV'], decay_rate=0.5)
df['radio_adstock'] = geometric_adstock(df['Radio'], decay_rate=0.3)

# --- Standardize adstocked features ---
scaler = StandardScaler()
# Standardize the adstocked values directly, without saturation for now
df[['tv_adstock_scaled', 'radio_adstock_scaled']] = scaler.fit_transform(df[['tv_adstock', 'radio_adstock']])

# Prepare data for PyMC - Use scaled adstocked values directly
X1 = df['tv_adstock_scaled'].values
X2 = df['radio_adstock_scaled'].values
y = df['NewVolSales'].values

# --- Sanity checks for inputs ---
assert np.isfinite(y).all(), "Non-finite values in target variable y"
assert np.isfinite(X1).all(), "Non-finite values in tv_adstock_scaled"
assert np.isfinite(X2).all(), "Non-finite values in radio_adstock_scaled"

# --- Bayesian MMM Model (Simplified) ---
with pm.Model() as mmm_model:
    baseline = pm.Normal('baseline', mu=np.mean(y), sigma=10)
    beta_tv = pm.Normal('beta_tv', mu=0, sigma=5)
    beta_radio = pm.Normal('beta_radio', mu=0, sigma=5)
    # Removed synergy term
    sigma = pm.HalfNormal('sigma', sigma=10)

    expected_sales = baseline + beta_tv * X1 + beta_radio * X2 # Simplified linear model
    # Check for NaNs or Infs in mu before likelihood (during sampling)
    # This check can't be done directly like this within the model
    # Instead, rely on the sampler to report issues and the input data to be clean.

    sales = pm.Normal('sales', mu=expected_sales, sigma=sigma, observed=y)

    print("Sampling...")
    # Increased target_accept as suggested by previous warning
    idata = pm.sample(2000, tune=1000, chains=4, cores=1, target_accept=0.99)
    print("Sampling complete.")

# --- Posterior Plot ---
# Updated var_names to reflect simplified model
pm.plot_posterior(idata, var_names=['baseline', 'beta_tv', 'beta_radio'])
plt.suptitle("Posterior Distributions of Model Parameters (Simplified Model)", y=1.02)
plt.show()

# --- Posterior Predictive Check ---
with mmm_model:
     # Use the model context where idata was generated
    ppc = pm.sample_posterior_predictive(idata, var_names=["sales"], random_seed=42, extend_inferencedata=True)

predicted_sales = ppc.posterior_predictive['sales'].mean(dim=["chain", "draw"]).values

plt.figure(figsize=(10, 5))
sns.histplot(y, label="Observed Sales", kde=True, stat='density', color='blue')
sns.histplot(predicted_sales, label="Predicted Sales", kde=True, stat='density', color='orange')
plt.title("Posterior Predictive Check")
plt.xlabel("Sales")
plt.legend()
plt.show()

# --- Sales Contribution ---
# Use az.summary for means
summary = az.summary(idata, var_names=['baseline', 'beta_tv', 'beta_radio'])

baseline_contribution = summary.loc['baseline', 'mean']
beta_tv_mean = summary.loc['beta_tv', 'mean']
beta_radio_mean = summary.loc['beta_radio', 'mean']

# Contributions based on scaled adstock means (interpretation changes slightly without saturation)
# For a more meaningful contribution, we'd ideally work with original scale or transformed scale *before* standardization.
# Let's calculate contribution based on scaled means for now as a relative indicator.
tv_contribution_scaled = beta_tv_mean * df['tv_adstock_scaled'].mean()
radio_contribution_scaled = beta_radio_mean * df['radio_adstock_scaled'].mean()


contributions_scaled = {
    'Baseline': baseline_contribution,
    'TV (Scaled Adstock)': tv_contribution_scaled,
    'Radio (Scaled Adstock)': radio_contribution_scaled,
}

# --- Plot Contributions ---
plt.figure(figsize=(10, 6))
plt.bar(contributions_scaled.keys(), contributions_scaled.values(), color='steelblue')
plt.title('Average Contribution to Sales (Simplified Model - Scaled Adstock)')
plt.ylabel('Sales Contribution')
plt.grid(True, axis='y', linestyle='--', alpha=0.5)
plt.show()

# --- Model Insights ---
print("\n--- Model Insights (Simplified Model) ---")
print(f"Baseline sales (no marketing): {baseline_contribution:.2f}")
print(f"TV contribution (Scaled Adstock): {tv_contribution_scaled:.2f}")
print(f"Radio contribution (Scaled Adstock): {radio_contribution_scaled:.2f}")


# --- ROI Estimates (Simplified Interpretation) ---
# With scaled variables, direct ROI in sales units per dollar is not straightforward.
# The betas represent the expected change in sales for a one-unit change in the *scaled* adstock variable.
# We can look at the betas as relative indicators of impact on the scaled adstock level.

print("\n--- Scaled Adstock Beta Estimates (Relative Impact) ---")
print(f"TV Scaled Adstock Beta: {beta_tv_mean:.2f}")
print(f"Radio Scaled Adstock Beta: {beta_radio_mean:.2f}")

# --- Simulation Function (Simplified) ---
def simulate_sales_simplified(tv_spend, radio_spend, decay_tv=0.5, decay_radio=0.3):
    # Ensure inputs are non-negative
    tv_spend_clean = np.maximum(tv_spend, 0)
    radio_spend_clean = np.maximum(radio_spend, 0)

    tv_adstock = geometric_adstock([tv_spend_clean]*10, decay_tv)[-1] # Simulate over a few periods
    radio_adstock = geometric_adstock([radio_spend_clean]*10, decay_radio)[-1]

    # Standardize using the scaler fitted on training data
    sim_data = pd.DataFrame([[tv_adstock, radio_adstock]], columns=['tv_adstock', 'radio_adstock'])
    sim_scaled = scaler.transform(sim_data)

    tv_std_val = sim_scaled[0, 0]
    radio_std_val = sim_scaled[0, 1]

    # Get mean parameter values from the trace
    baseline_mean_sim = az.summary(idata, var_names=['baseline']).loc['baseline', 'mean']
    beta_tv_mean_sim = az.summary(idata, var_names=['beta_tv']).loc['beta_tv', 'mean']
    beta_radio_mean_sim = az.summary(idata, var_names=['beta_radio']).loc['beta_radio', 'mean']

    expected = (
        baseline_mean_sim
        + beta_tv_mean_sim * tv_std_val
        + beta_radio_mean_sim * radio_std_val
    )
    return expected

# --- Example What-if Simulation (Simplified) ---
# Use reasonable spend values based on the data range
example_tv_spend = df['TV'].mean()
example_radio_spend = df['Radio'].mean()

sim_sales = simulate_sales_simplified(tv_spend=example_tv_spend, radio_spend=example_radio_spend)
print("\n--- What-if Simulation (Simplified Model) ---")
print(f"Expected sales with TV=${example_tv_spend:.0f} and Radio=${example_radio_spend:.0f}: {sim_sales:.2f}")

# --- Sales vs Spend Plot (Simplified) ---
tv_range = np.linspace(0, df['TV'].max() * 2, 50) # Extend range beyond observed data
radio_range = np.linspace(0, df['Radio'].max() * 2, 50)

# Use mean spend for the fixed variable
fixed_radio_spend = df['Radio'].mean()
fixed_tv_spend = df['TV'].mean()

tv_sim = [simulate_sales_simplified(tv, fixed_radio_spend) for tv in tv_range]
radio_sim = [simulate_sales_simplified(fixed_tv_spend, r) for r in radio_range]


plt.figure(figsize=(12, 5))
plt.plot(tv_range, tv_sim, label=f'Varying TV (Radio fixed at ${fixed_radio_spend:.0f})')
plt.plot(radio_range, radio_sim, label=f'Varying Radio (TV fixed at ${fixed_tv_spend:.0f})')
plt.xlabel('Media Spend ($)')
plt.ylabel('Expected Sales')
plt.title('What-if Sales Simulation (Simplified Model)')
plt.legend()
plt.grid(True)
plt.show()

# Removed Elasticity Curve for simplicity

# --- Install Required Packages ---
# !pip install pymc arviz seaborn matplotlib scikit-learn kagglehub

# --- Imports ---
import kagglehub
import pandas as pd
import numpy as np
import pymc as pm
import arviz as az
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
import os

# --- Download Dataset ---
path = kagglehub.dataset_download("veer06b/marrket-mix-dataset")
df = pd.read_csv(os.path.join(path, "data.csv"))
df.head()

# --- Feature Engineering ---
df["TV_Radio"] = df["TV"] * df["Radio"]

# --- Standardize Features ---
X = df[["TV", "Radio", "TV_Radio"]]
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
df_scaled = pd.DataFrame(X_scaled, columns=["TV", "Radio", "TV_Radio"])
df_scaled["Sales"] = df["Sales"]

# --- Modeling ---
X_tv = df_scaled["TV"].values
X_radio = df_scaled["Radio"].values
X_synergy = df_scaled["TV_Radio"].values
y = df_scaled["Sales"].values

with pm.Model() as mmm_model:
    # Priors
    baseline = pm.Normal("baseline", mu=np.mean(y), sigma=10)
    beta_tv = pm.Normal("beta_tv", mu=0, sigma=1)
    beta_radio = pm.Normal("beta_radio", mu=0, sigma=1)
    synergy_tv_radio = pm.Normal("synergy_tv_radio", mu=0, sigma=1)
    sigma = pm.HalfNormal("sigma", sigma=5)

    # Mean sales
    mu = baseline + beta_tv * X_tv + beta_radio * X_radio + synergy_tv_radio * X_synergy

    # Likelihood
    sales = pm.Normal("sales", mu=mu, sigma=sigma, observed=y)

    # Sample from the posterior
    print("Sampling...")
    idata = pm.sample(2000, tune=1000, target_accept=0.95, random_seed=42)
    print("Sampling complete.")

# --- Summary of Posterior ---
summary = az.summary(idata, var_names=["baseline", "beta_tv", "beta_radio", "synergy_tv_radio", "sigma"])
print(summary)

# --- Plot Posterior Distributions ---
az.plot_posterior(idata, var_names=["baseline", "beta_tv", "beta_radio", "synergy_tv_radio"])
plt.show()

# --- Posterior Predictive Check ---
with mmm_model:
    ppc = pm.sample_posterior_predictive(idata, var_names=["sales"], random_seed=42)

# Plot actual vs predicted sales
observed_sales = y
predicted_sales = ppc.posterior_predictive['sales'].mean(dim=["chain", "draw"]).values

plt.figure(figsize=(10, 5))
sns.histplot(observed_sales, label="Observed Sales", kde=True, color='blue', stat='density')
sns.histplot(predicted_sales, label="Predicted Sales", kde=True, color='orange', stat='density')
plt.title("Posterior Predictive Check")
plt.xlabel("Sales")
plt.legend()
plt.show()

# --- Imports ---
# pip install pymc seaborn matplotlib scikit-learn kagglehub

import kagglehub
import pandas as pd
import numpy as np
import pymc as pm
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
import os

# --- Load Dataset ---
path = kagglehub.dataset_download("veer06b/marrket-mix-dataset")
df = pd.read_csv(f"{path}/mktmix.csv")
df['Radio'] = df['Radio ']
del df['Radio ']

# --- Adstock Transformation ---
def geometric_adstock(spend, alpha):
    adstocked = []
    carryover = 0
    for s in spend:
        val = s + alpha * carryover
        adstocked.append(val)
        carryover = val
    return np.array(adstocked)

df['tv_adstock'] = geometric_adstock(df['TV'], 0.5)
df['radio_adstock'] = geometric_adstock(df['Radio'], 0.3)

# --- Hill (Saturation) Transformation ---
def hill_transform(x, alpha, gamma):
    return (x ** alpha) / (x ** alpha + gamma ** alpha)

# Initial guess params for Hill
alpha_tv, gamma_tv = 1.5, 100
alpha_radio, gamma_radio = 1.3, 30

df['tv_saturated'] = hill_transform(df['tv_adstock'], alpha_tv, gamma_tv)
df['radio_saturated'] = hill_transform(df['radio_adstock'], alpha_radio, gamma_radio)

# Save raw means (for contributions)
tv_raw = df['tv_saturated'].mean()
radio_raw = df['radio_saturated'].mean()
tv_radio_synergy_raw = (df['tv_saturated'] * df['radio_saturated']).mean()

# Standardize
scaler = StandardScaler()
df[['tv_saturated', 'radio_saturated']] = scaler.fit_transform(df[['tv_saturated', 'radio_saturated']])

X1 = df['tv_saturated'].values
X2 = df['radio_saturated'].values
y = df['NewVolSales'].values

# --- PyMC Bayesian Model (Meridian Style) ---
with pm.Model() as mmm_model:
    # Hierarchical Priors
    mu_beta = pm.Normal('mu_beta', mu=0, sigma=2)
    sigma_beta = pm.HalfNormal('sigma_beta', 2)

    beta_tv = pm.Normal('beta_tv', mu=mu_beta, sigma=sigma_beta)
    beta_radio = pm.Normal('beta_radio', mu=mu_beta, sigma=sigma_beta)
    synergy = pm.Normal('synergy', mu=0, sigma=1)

    baseline = pm.Normal('baseline', mu=np.mean(y), sigma=10)
    sigma = pm.HalfNormal('sigma', sigma=10)

    mu_sales = (
        baseline +
        beta_tv * X1 +
        beta_radio * X2 +
        synergy * X1 * X2
    )

    sales = pm.Normal('sales', mu=mu_sales, sigma=sigma, observed=y)

    print("Sampling with hierarchical priors...")
    idata = pm.sample(2000, tune=1000, target_accept=0.95, chains=4, cores=1)

# --- Posterior Plot ---
pm.plot_posterior(idata, var_names=['baseline', 'beta_tv', 'beta_radio', 'synergy'])
plt.suptitle("Posterior Distributions", y=1.02)
plt.show()

# --- Contribution Analysis ---
baseline_val = idata.posterior['baseline'].mean().item()
beta_tv_val = idata.posterior['beta_tv'].mean().item()
beta_radio_val = idata.posterior['beta_radio'].mean().item()
synergy_val = idata.posterior['synergy'].mean().item()

tv_contrib = beta_tv_val * tv_raw
radio_contrib = beta_radio_val * radio_raw
synergy_contrib = synergy_val * tv_radio_synergy_raw

contributions = {
    'Baseline': baseline_val,
    'TV': tv_contrib,
    'Radio': radio_contrib,
    'TV-Radio Synergy': synergy_contrib
}

# --- Plot Contributions ---
plt.figure(figsize=(10, 6))
plt.bar(contributions.keys(), contributions.values())
plt.title("Average Contribution to Sales")
plt.ylabel("Sales Units")
plt.grid(True, axis='y')
plt.show()

# --- ROI from Posterior Distribution ---
tv_std = df['tv_saturated'].std()
radio_std = df['radio_saturated'].std()

roi_tv_post = idata.posterior['beta_tv'] / tv_std
roi_radio_post = idata.posterior['beta_radio'] / radio_std

print("\n--- Posterior Marginal ROI ---")
print(f"TV ROI Mean: {roi_tv_post.mean().item():.2f}")
print(f"Radio ROI Mean: {roi_radio_post.mean().item():.2f}")

# --- Budget Allocation (Posterior Mean ROI) ---
total_budget = 100_000
roi_tv = roi_tv_post.mean().item()
roi_radio = roi_radio_post.mean().item()
total_roi = roi_tv + roi_radio

tv_budget = roi_tv / total_roi * total_budget
radio_budget = roi_radio / total_roi * total_budget

print("\n--- Budget Allocation ---")
print(f"TV: ${tv_budget:.0f}, Radio: ${radio_budget:.0f}")

# --- Media Mix Simulator ---
def simulate_sales(tv_spend, radio_spend, alpha_tv=0.5, alpha_radio=0.3):
    # Apply adstock
    tv_ads = geometric_adstock([tv_spend]*10, alpha_tv)[-1]
    radio_ads = geometric_adstock([radio_spend]*10, alpha_radio)[-1]

    # Hill transform
    tv_sat = hill_transform(tv_ads, alpha_tv, gamma_tv)
    radio_sat = hill_transform(radio_ads, alpha_radio, gamma_radio)

    # Standardize
    tv_std_val = (tv_sat - tv_raw) / tv_std
    radio_std_val = (radio_sat - radio_raw) / radio_std

    return (
        baseline_val +
        beta_tv_val * tv_std_val +
        beta_radio_val * radio_std_val +
        synergy_val * tv_std_val * radio_std_val
    )

# --- What-if Analysis ---
sim_sales = simulate_sales(30000, 20000)
print("\n--- What-if Sales Simulation ---")
print(f"Sales with TV=$30K and Radio=$20K: {sim_sales:.2f}")

# --- ROI Curves ---
tv_range = np.linspace(0, 100000, 50)
radio_range = np.linspace(0, 100000, 50)
tv_sim = [simulate_sales(tv, 20000) for tv in tv_range]
radio_sim = [simulate_sales(30000, r) for r in radio_range]

plt.figure(figsize=(12, 5))
plt.plot(tv_range, tv_sim, label='TV ROI (Radio=$20k)')
plt.plot(radio_range, radio_sim, label='Radio ROI (TV=$30k)')
plt.xlabel("Spend ($)")
plt.ylabel("Expected Sales")
plt.title("Marginal ROI Simulation")
plt.legend()
plt.grid(True)
plt.show()

# --- Install Required Packages if not already ---
# pip install pymc seaborn matplotlib scikit-learn pandas numpy arviz kagglehub

import pandas as pd
import numpy as np
import pymc as pm
import matplotlib.pyplot as plt
import seaborn as sns
import arviz as az
from sklearn.preprocessing import StandardScaler
import kagglehub

path = kagglehub.dataset_download("veer06b/marrket-mix-dataset")
print("Path to dataset files:", path)

# Load and inspect data
df = pd.read_csv(f"{path}/mktmix.csv")
df['Radio'] = df['Radio ']
del df['Radio ']

# --- Geometric Adstock ---
def geometric_adstock(spend, alpha):
    adstocked = []
    carryover = 0
    # Handle potential NaNs in input spend
    spend_clean = np.nan_to_num(spend, nan=0.0, posinf=0.0, neginf=0.0)
    for s in spend_clean:
        val = s + alpha * carryover
        adstocked.append(val)
        carryover = val
    return np.array(adstocked)

df['tv_adstock'] = geometric_adstock(df['TV'], alpha=0.5)
df['radio_adstock'] = geometric_adstock(df['Radio'], alpha=0.3)

# --- Hill (Saturation) Transformation ---
def hill_transform(x, alpha, gamma):
    # Ensure x is non-negative and add a small epsilon to avoid division by zero
    x_clean = np.maximum(x, 1e-9) # Ensure non-negative and slightly above zero
    # Add a small epsilon to the denominator as well
    denominator = x_clean ** alpha + gamma ** alpha
    return (x_clean ** alpha) / (denominator + 1e-9)


# Hill parameters
alpha_tv, gamma_tv = 1.5, 100
alpha_radio, gamma_radio = 1.3, 30

# Handle potential NaNs in adstock before Hill transform
df['tv_adstock'].fillna(df['tv_adstock'].mean(), inplace=True)
df['radio_adstock'].fillna(df['radio_adstock'].mean(), inplace=True)


df['tv_saturated'] = hill_transform(df['tv_adstock'], alpha_tv, gamma_tv)
df['radio_saturated'] = hill_transform(df['radio_adstock'], alpha_radio, gamma_radio)

# Save raw means (for contribution decomposition)
tv_raw = df['tv_saturated'].mean()
radio_raw = df['radio_saturated'].mean()
tv_radio_synergy_raw = (df['tv_saturated'] * df['radio_saturated']).mean()


# --- Standardize Saturated Inputs ---
scaler = StandardScaler()
df[['tv_saturated', 'radio_saturated']] = scaler.fit_transform(df[['tv_saturated', 'radio_saturated']])

# Recalculate std after standardization
tv_std = df['tv_saturated'].std()
radio_std = df['radio_saturated'].std()

X1 = df['tv_saturated'].values
X2 = df['radio_saturated'].values
y = df['NewVolSales'].values

# --- Sanity checks for inputs after all transformations and standardization ---
assert np.isfinite(y).all(), "Non-finite values in target variable y after cleaning"
assert np.isfinite(X1).all(), "Non-finite values in tv_saturated after transformation and standardization"
assert np.isfinite(X2).all(), "Non-finite values in radio_saturated after transformation and standardization"


# --- PyMC Bayesian Model (Simplified - removed hierarchical priors for now) ---
with pm.Model() as mmm_model:
    # Priors
    beta_tv = pm.Normal('beta_tv', mu=0, sigma=5)
    beta_radio = pm.Normal('beta_radio', mu=0, sigma=5)
    synergy = pm.Normal('synergy', mu=0, sigma=2) # Increased sigma slightly
    baseline = pm.Normal('baseline', mu=np.mean(y), sigma=5000) # Use a wider prior for baseline
    sigma = pm.HalfNormal('sigma', sigma=5000) # Use a wider prior for sigma

    # Model equation
    mu_sales = (
        baseline +
        beta_tv * X1 +
        beta_radio * X2 +
        synergy * X1 * X2
    )

    # Likelihood
    sales = pm.Normal('sales', mu=mu_sales, sigma=sigma, observed=y)

    print("Sampling...")
    idata = pm.sample(2000, tune=1000, target_accept=0.99, chains=4, cores=1) # Increased target_accept
    print("Sampling complete.")

# --- Posterior Visualization ---
pm.plot_posterior(idata, var_names=['baseline', 'beta_tv', 'beta_radio', 'synergy'])
plt.suptitle("Posterior Distributions", y=1.02)
plt.show()

# --- Contribution Decomposition ---
baseline_val = idata.posterior['baseline'].mean().item()
beta_tv_val = idata.posterior['beta_tv'].mean().item()
beta_radio_val = idata.posterior['beta_radio'].mean().item()
synergy_val = idata.posterior['synergy'].mean().item()

tv_contrib = beta_tv_val * tv_raw
radio_contrib = beta_radio_val * radio_raw
synergy_contrib = synergy_val * tv_radio_synergy_raw

contributions = {
    'Baseline': baseline_val,
    'TV': tv_contrib,
    'Radio': radio_contrib,
    'TV-Radio Synergy': synergy_contrib
}

# --- Plot Contributions ---
plt.figure(figsize=(10, 6))
plt.bar(contributions.keys(), contributions.values(), color='skyblue')
plt.title("Average Contribution to Sales")
plt.ylabel("Sales Units")
plt.grid(True, axis='y')
plt.show()

# --- Posterior Marginal ROI ---
# Recalculate std after standardization
tv_std = df['tv_saturated'].std()
radio_std = df['radio_saturated'].std()

# Note: ROI calculated this way is relative to the *standardized transformed* spend.
# A more interpretable ROI requires simulation on the original spend scale.
roi_tv_post = idata.posterior['beta_tv'] / tv_std
roi_radio_post = idata.posterior['beta_radio'] / radio_std

roi_tv = roi_tv_post.mean().item()
roi_radio = roi_radio_post.mean().item()

print("\n--- Posterior Marginal ROI (relative to standardized transformed spend) ---")
print(f"TV ROI Mean: {roi_tv:.2f}")
print(f"Radio ROI Mean: {roi_radio:.2f}")

# --- Budget Allocation (Based on relative ROI) ---
# This allocation is based on the relative impact on the standardized transformed scale,
# not direct sales units per dollar on the original spend scale.
total_budget = 100_000
# Avoid division by zero if total_roi is zero or very close to zero
total_roi = roi_tv + roi_radio
if abs(total_roi) > 1e-9:
    tv_budget = roi_tv / total_roi * total_budget
    radio_budget = roi_radio / total_roi * total_budget
    print("\n--- Budget Allocation (Based on Relative ROI) ---")
    print(f"Total Budget: ${total_budget:,.0f}")
    print(f"TV: ${tv_budget:,.0f}")
    print(f"Radio: ${radio_budget:,.0f}")
else:
    print("\n--- Budget Allocation ---")
    print("Cannot calculate budget allocation based on relative ROI as total relative ROI is zero.")
    print(f"Total Budget: ${total_budget:,.0f}")


# --- Media Mix Simulator Function (Updated to use idata) ---
def simulate_sales(tv_spend, radio_spend, decay_tv=0.5, decay_radio=0.3, alpha_tv=1.5, gamma_tv=100, alpha_radio=1.3, gamma_radio=30):
    # Ensure inputs are non-negative
    tv_spend_clean = np.maximum(tv_spend, 0)
    radio_spend_clean = np.maximum(radio_spend, 0)

    tv_adstock = geometric_adstock([tv_spend_clean]*10, decay_tv)[-1] # Simulate over a few periods
    radio_adstock = geometric_adstock([radio_spend_clean]*10, decay_radio)[-1]

    tv_sat = hill_transform(tv_adstock, alpha_tv, gamma_tv)
    radio_sat = hill_transform(radio_adstock, alpha_radio, gamma_radio)

    # Standardize using the original scaler fitted on training data
    sim_data = pd.DataFrame([[tv_sat, radio_sat]], columns=['tv_saturated', 'radio_saturated'])
    # Ensure sim_data columns match scaler's training features
    sim_scaled = scaler.transform(sim_data)

    tv_std_val = sim_scaled[0, 0]
    radio_std_val = sim_scaled[0, 1]

    # Get mean parameter values from the trace
    baseline_mean_sim = az.summary(idata, var_names=['baseline']).loc['baseline', 'mean']
    beta_tv_mean_sim = az.summary(idata, var_names=['beta_tv']).loc['beta_tv', 'mean']
    beta_radio_mean_sim = az.summary(idata, var_names=['beta_radio']).loc['beta_radio', 'mean']
    synergy_mean_sim = az.summary(idata, var_names=['synergy']).loc['synergy', 'mean']


    expected = (
        baseline_mean_sim
        + beta_tv_mean_sim * tv_std_val
        + beta_radio_mean_sim * radio_std_val
        + synergy_mean_sim * tv_std_val * radio_std_val
    )
    return expected


# --- What-if Simulation ---
sim_sales = simulate_sales(30000, 20000)
print("\n--- What-if Sales Simulation ---")
print(f"Expected sales with TV=$30,000 and Radio=$20,000: {sim_sales:.2f}")

# --- ROI Curve Visualization ---
tv_range = np.linspace(0, 100000, 50)
radio_range = np.linspace(0, 100000, 50)
tv_sim = [simulate_sales(tv, 20000) for tv in tv_range]
radio_sim = [simulate_sales(30000, r) for r in radio_range]

plt.figure(figsize=(12, 5))
plt.plot(tv_range, tv_sim, label='TV Spend (Radio fixed at $20k)')
plt.plot(radio_range, radio_sim, label='Radio Spend (TV fixed at $30k)')
plt.xlabel("Spend ($)")
plt.ylabel("Expected Sales")
plt.title("What-if Sales Simulation")
plt.legend()
plt.grid(True)
plt.show()

### Main code

# --- Install & Imports ---
# pip install pymc seaborn matplotlib scikit-learn kagglehub

import kagglehub
import pandas as pd
import numpy as np
import pymc as pm
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
import os

# --- Download dataset ---
path = kagglehub.dataset_download("veer06b/marrket-mix-dataset")
print("Path to dataset files:", path)

# Load and inspect data
df = pd.read_csv(f"{path}/mktmix.csv")
print(df.head())

# --- Preprocessing ---
df['Radio'] = df['Radio ']  # Clean column name
del df['Radio ']

# --- Adstock Function ---
def geometric_adstock(spend, decay_rate):
    adstocked = []
    carryover = 0
    for s in spend:
        val = s + decay_rate * carryover
        adstocked.append(val)
        carryover = val
    return np.array(adstocked)

# Apply adstock
df['tv_adstock'] = geometric_adstock(df['TV'], decay_rate=0.5)
df['radio_adstock'] = geometric_adstock(df['Radio'], decay_rate=0.3)

# --- Hill Saturation Function ---
def hill_transform(x, alpha=1.5, theta=100):
    return (x ** alpha) / (x ** alpha + theta ** alpha)

# Apply Hill transformation
df['tv_saturated'] = hill_transform(df['tv_adstock'], alpha=1.5, theta=100)
df['radio_saturated'] = hill_transform(df['radio_adstock'].fillna(df['radio_adstock'].mean()), alpha=1.5, theta=100)

# ðŸ‘‰ Save raw means before standardizing (for contribution calc later)
tv_sat_mean_raw = df['tv_saturated'].mean()
radio_sat_mean_raw = df['radio_saturated'].mean()
tv_radio_synergy_raw = (df['tv_saturated'] * df['radio_saturated']).mean()

# Standardize for modeling
scaler = StandardScaler()
df[['tv_saturated', 'radio_saturated']] = scaler.fit_transform(df[['tv_saturated', 'radio_saturated']])

# Model inputs
X1 = df['tv_saturated'].values
X2 = df['radio_saturated'].values
y = df['NewVolSales'].values

# --- PyMC Bayesian Model ---
with pm.Model() as mmm_model:
    baseline = pm.Normal('baseline', mu=np.mean(y), sigma=10)
    beta_tv = pm.Normal('beta_tv', mu=0, sigma=5)
    beta_radio = pm.Normal('beta_radio', mu=0, sigma=5)
    synergy_tv_radio = pm.Normal('synergy_tv_radio', mu=0, sigma=2)
    sigma = pm.HalfNormal('sigma', sigma=10)

    expected_sales = (
        baseline +
        beta_tv * X1 +
        beta_radio * X2 +
        synergy_tv_radio * X1 * X2
    )

    sales = pm.Normal('sales', mu=expected_sales, sigma=sigma, observed=y)

    print("Starting MCMC sampling...")
    idata = pm.sample(2000, tune=1000, chains=4, cores=1, target_accept=0.95)
    print("Sampling complete.")

# --- Posterior Visualization ---
pm.plot_posterior(idata, var_names=['baseline', 'beta_tv', 'beta_radio', 'synergy_tv_radio'])
plt.suptitle("Posterior Distributions of Model Parameters", y=1.02)
plt.show()

# --- Sales Contribution Decomposition ---
baseline_contribution = idata.posterior['baseline'].mean().item()
beta_tv_mean = idata.posterior['beta_tv'].mean().item()
beta_radio_mean = idata.posterior['beta_radio'].mean().item()
synergy_mean = idata.posterior['synergy_tv_radio'].mean().item()

# âœ… Use raw means here
tv_contribution = beta_tv_mean * tv_sat_mean_raw
radio_contribution = beta_radio_mean * radio_sat_mean_raw
synergy_contribution = synergy_mean * tv_radio_synergy_raw

contributions = {
    'Baseline': baseline_contribution,
    'TV': tv_contribution,
    'Radio': radio_contribution,
    'TV-Radio Synergy': synergy_contribution
}

# --- Plot Contributions ---
plt.figure(figsize=(10, 6))
plt.bar(contributions.keys(), contributions.values(), color='steelblue')
plt.title('Average Contribution to Sales')
plt.ylabel('Sales Contribution')
plt.grid(True, axis='y', linestyle='--', alpha=0.5)
plt.show()

# --- Print Insights ---
print("\n--- Model Insights ---")
print(f"Baseline sales (no marketing): {baseline_contribution:.2f}")
print(f"TV contribution: {tv_contribution:.2f}")
print(f"Radio contribution: {radio_contribution:.2f}")
print(f"TV-Radio Synergy: {synergy_contribution:.2f}")
if synergy_contribution > 0:
    print("ðŸŸ¢ Positive synergy detected between TV and Radio.")
else:
    print("ðŸ”´ Negative or no synergy between TV and Radio.")

# --- Marginal ROI Calculation ---
tv_std = df['tv_saturated'].std()
radio_std = df['radio_saturated'].std()

roi_tv = beta_tv_mean / tv_std
roi_radio = beta_radio_mean / radio_std

print("\n--- Marginal ROI Estimates ---")
print(f"TV Marginal ROI: {roi_tv:.2f} units of sales per $1 spend")
print(f"Radio Marginal ROI: {roi_radio:.2f} units of sales per $1 spend")

# --- Optimal Budget Allocation ---
total_budget = 100_000  # Example budget
total_roi = roi_tv + roi_radio
tv_budget = (roi_tv / total_roi) * total_budget
radio_budget = (roi_radio / total_roi) * total_budget

print("\n--- Recommended Budget Allocation (Based on ROI) ---")
print(f"Total Budget: ${total_budget:,.0f}")
print(f"Allocate to TV: ${tv_budget:,.0f}")
print(f"Allocate to Radio: ${radio_budget:,.0f}")

# --- Media Mix Simulator Function ---
def simulate_sales(tv_spend, radio_spend, decay_tv=0.5, decay_radio=0.3):
    tv_adstock = geometric_adstock([tv_spend]*10, decay_tv)[-1]
    radio_adstock = geometric_adstock([radio_spend]*10, decay_radio)[-1]

    tv_sat = hill_transform(tv_adstock, alpha=1.5, theta=100)
    radio_sat = hill_transform(radio_adstock, alpha=1.5, theta=100)

    tv_std_val = (tv_sat - tv_sat_mean_raw) / tv_std
    radio_std_val = (radio_sat - radio_sat_mean_raw) / radio_std

    expected = (
        baseline_contribution +
        beta_tv_mean * tv_std_val +
        beta_radio_mean * radio_std_val +
        synergy_mean * tv_std_val * radio_std_val
    )
    return expected

# --- Example What-if Simulation ---
sim_sales = simulate_sales(tv_spend=30000, radio_spend=20000)
print("\n--- What-if Simulation ---")
print(f"Expected sales with TV=$30,000 and Radio=$20,000: {sim_sales:.2f}")

# --- ROI vs Spend Plot ---
tv_range = np.linspace(0, 100000, 50)
radio_range = np.linspace(0, 100000, 50)
tv_sim = [simulate_sales(tv, 20000) for tv in tv_range]
radio_sim = [simulate_sales(30000, r) for r in radio_range]

plt.figure(figsize=(12, 5))
plt.plot(tv_range, tv_sim, label='Varying TV (Radio fixed at $20k)')
plt.plot(radio_range, radio_sim, label='Varying Radio (TV fixed at $30k)')
plt.xlabel('Media Spend ($)')
plt.ylabel('Expected Sales')
plt.title('What-if Sales Simulation')
plt.legend()
plt.grid(True)
plt.show()

# --- Optional: Hill vs Log1p Comparison Plot ---
x_vals = np.linspace(0, 300, 100)
plt.figure(figsize=(8, 5))
plt.plot(x_vals, np.log1p(x_vals), label="Log1p", linestyle='--')
plt.plot(x_vals, hill_transform(x_vals, alpha=1.5, theta=100), label="Hill (Î±=1.5, Î¸=100)")
plt.xlabel("Adstock Spend")
plt.ylabel("Saturation Output")
plt.title("Saturation Functions: Log vs Hill")
plt.legend()
plt.grid(True)
plt.show()

